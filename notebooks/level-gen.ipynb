{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "79dde41a",
   "metadata": {},
   "source": [
    "## Load Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2312605",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lelie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using shyamsn97/Mario-GPT2-700-context-length lm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lelie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers-4.30.2-py3.11.egg\\transformers\\models\\auto\\modeling_auto.py:1362: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at shyamsn97/Mario-GPT2-700-context-length were not used when initializing GPT2LMHeadModel: ['transformer.h.3.crossattention.bias', 'transformer.h.4.crossattention.bias', 'transformer.h.2.crossattention.masked_bias', 'transformer.h.2.crossattention.bias', 'transformer.h.5.crossattention.masked_bias', 'transformer.h.1.crossattention.masked_bias', 'transformer.h.5.crossattention.bias', 'transformer.h.1.crossattention.bias', 'transformer.h.0.crossattention.masked_bias', 'transformer.h.3.crossattention.masked_bias', 'transformer.h.4.crossattention.masked_bias', 'transformer.h.0.crossattention.bias']\n",
      "- This IS expected if you are initializing GPT2LMHeadModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing GPT2LMHeadModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using shyamsn97/Mario-GPT2-700-context-length tokenizer\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from mario_gpt import MarioLM, SampleOutput\n",
    "import os, random\n",
    "from mario_gpt.utils  import  view_level, convert_level_to_png, join_list_of_list, characterize\n",
    "mario_lm = MarioLM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0e1c58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')\n",
    "# device = torch.device('cpu')\n",
    "mario_lm = mario_lm.to(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a8fad057",
   "metadata": {},
   "source": [
    "## Generating Levels"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fd7f642c",
   "metadata": {},
   "source": [
    "### Config dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "927bfdad",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_levels = 100\n",
    "prompts_folder = \"./prompts\"\n",
    "levels_folder = \"./level\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "054cbddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipes = [\"no\", \"little\", \"some\", \"many\"]\n",
    "enemies = [\"no\", \"little\", \"some\", \"many\"]\n",
    "blocks = [\"little\", \"some\", \"many\"]\n",
    "elevation = [\"low\", \"high\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "868ba3b2",
   "metadata": {},
   "source": [
    "### Start gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "39d93d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = []\n",
    "for i in range(num_levels):\n",
    "    # Tạo prompts ngẫu nhiên\n",
    "    prompt_pipes = random.choice(pipes) + \" pipes\"\n",
    "    prompt_enemies = random.choice(enemies) + \" enemies\"\n",
    "    prompt_blocks = random.choice(blocks) + \" blocks\"\n",
    "    prompt_elevation = random.choice(elevation) + \" elevation\"\n",
    "    prompts.append(f\"{prompt_pipes}, {prompt_enemies}, {prompt_blocks}, {prompt_elevation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "33b92b6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "shape: torch.Size([15, 672]), torch.Size([15, 1401]) first: 56, last: 13: 100%|██████████| 1400/1400 [1:28:26<00:00,  3.79s/it]\n"
     ]
    }
   ],
   "source": [
    "# Sinh level mới\n",
    "generated_level = mario_lm.sample(\n",
    "    prompts=prompts,\n",
    "    num_steps=1400,\n",
    "    temperature=2.0,\n",
    "    use_tqdm=True\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "89bd5137",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "j = 0\n",
    "for lv in generated_level:\n",
    "    i = i + 1\n",
    "    level_filename = f\"level_{i+1}.txt\"\n",
    "    level_filepath = os.path.join(levels_folder, level_filename)\n",
    "    with open(level_filepath, \"w\") as level_file:\n",
    "        level_file.write(\"\\n\".join(lv.level))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
